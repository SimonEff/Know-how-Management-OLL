{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import unicodedata\n",
    "\n",
    "# Third party\n",
    "import pandas as pd\n",
    "\n",
    "## PDF\n",
    "import fitz # pip install PyMuPDF\n",
    "## DOCX\n",
    "from docx import Document # pip install python-docx\n",
    "## DOC\n",
    "from striprtf.striprtf import rtf_to_text\n",
    "## RTF\n",
    "import textract # Needs dependencies, see https://textract.readthedocs.io/en/stable/installation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data folder exists:\t\t True\n",
      "File input folder exists:\t True\n",
      "File output folder exists:\t True\n"
     ]
    }
   ],
   "source": [
    "working_directory = os.path.split(os.getcwd())\n",
    "\n",
    "data_folder = os.path.join(working_directory[0], \"data\")\n",
    "print(\"Data folder exists:\\t\\t\", os.path.exists(data_folder))\n",
    "\n",
    "input_folder = os.path.join(working_directory[0], \"data\", \"unclean\")\n",
    "print(\"File input folder exists:\\t\", os.path.exists(input_folder))\n",
    "\n",
    "output_folder = os.path.join(working_directory[0], \"data\", \"clean\")\n",
    "print(\"File output folder exists:\\t\", os.path.exists(output_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_paths_from_directory(dir_path:str, abs_path:bool=False, file_exts:list=None, hidden:bool=False, sys_files:bool=False) -> list:\n",
    "    \"\"\"\n",
    "    Get a list of all files in a directory including subdirectories.\n",
    "\n",
    "    Args:\n",
    "    - dir_path (str): The path to the directory to search.\n",
    "    - hidden (list or None): Limit to specific file extension. Default is None.\n",
    "    - file_ext (bool): The file extension to search for. Default is None.\n",
    "    - abs_path (bool): Return absolute file paths. Default is False.\n",
    "    - hidden (bool): Include hidden files. Default is False.\n",
    "    - sys_files (bool): Include system files. Default is False.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of file paths. If abs_path is True, the file paths will be absolute. Otherwise, they will be relative.\n",
    "    \"\"\"\n",
    "    # Check if the directory exists\n",
    "    if not os.path.isdir(dir_path):\n",
    "        raise FileNotFoundError(f\"The directory '{dir_path}' does not exist.\")\n",
    "\n",
    "    # Get all files in the directory\n",
    "    file_list: list = []\n",
    "    for root, _, files in os.walk(dir_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_list.append(file_path)\n",
    "\n",
    "    # Remove spaces from the file names\n",
    "    ################# untested #################\n",
    "    for file_path in file_list:\n",
    "        get_clean_file_name(file_path)\n",
    "    ################# untested #################\n",
    "\n",
    "    # Filter the file list by file extension\n",
    "    if file_exts is not None:\n",
    "        _file_list: list = []\n",
    "        for file_ext in file_exts:\n",
    "            _file_list.extend([f for f in file_list if f.lower().endswith(file_ext)])\n",
    "        file_list = _file_list\n",
    "\n",
    "    # Filter the file list by hidden files\n",
    "    if not hidden:\n",
    "        file_list: list = [f for f in file_list if not os.path.basename(f).startswith(\".\")]\n",
    "\n",
    "    # Get the absolute file paths\n",
    "    if abs_path:\n",
    "        file_list: list = [os.path.abspath(f) for f in file_list]\n",
    "\n",
    "    # Filter the file list by system files\n",
    "    if not sys_files:\n",
    "        windows_sys_files = [\"desktop.ini\", \"thumbs.db\"]\n",
    "        mac_sys_files = [\".ds_store\"]\n",
    "        for sys_file in mac_sys_files + windows_sys_files:\n",
    "            file_list = [f for f in file_list if not os.path.basename(f).lower().startswith(sys_file)]\n",
    "\n",
    "    # Return the file list\n",
    "    return file_list\n",
    "\n",
    "def str_from_pdf_paths(pdf_paths: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get all text from a list of pdf files.\n",
    "    This function uses concurrent.futures.ProcessPoolExecutor to parallelize the extraction.\n",
    "    Uses PyMuPDF (fitz) as the pdf reader.\n",
    "\n",
    "    Args:\n",
    "    - pdf_paths (list): A list of paths to the pdf files.\n",
    "\n",
    "    Returns a DataFrame with columns:\n",
    "    - pdf_path (str): The path to the pdf file.\n",
    "    - status_ok (bool): True if the extraction was successful, False if not.\n",
    "    - result (str): The extracted text if successful, the error message if not.\n",
    "    \"\"\"\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        results = list(executor.map(str_from_pdf_path, pdf_paths))\n",
    "\n",
    "    return pd.DataFrame(results, columns=[\"pdf_path\", \"status_ok\", \"result\"])\n",
    "\n",
    "def str_from_pdf_path(pdf_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Get all text from a pdf file.\n",
    "    Uses PyMuPDF (fitz) as the pdf reader.\n",
    "\n",
    "    Returns dictionary with keys:\n",
    "    - status_ok: True if the extraction was successful, False if not.\n",
    "    - result: The extracted text if successful, the error message if not.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as file:\n",
    "            doc = fitz.open(file)\n",
    "            return {\n",
    "                \"path\": pdf_path,\n",
    "                \"status_ok\": True,\n",
    "                \"result\": \" \".join([page.get_text() for page in doc])\n",
    "            }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"path\": pdf_path,\n",
    "            \"status_ok\": False,\n",
    "            \"result\": str(e)\n",
    "        }\n",
    "    \n",
    "def get_clean_file_name(path: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove spaces from the file name.\n",
    "\n",
    "    Args:\n",
    "    - path (str): The path to the file.\n",
    "\n",
    "    Returns:\n",
    "    - str: The new path to the file.\n",
    "    \"\"\"\n",
    "    file_name = os.path.basename(path)\n",
    "    new_file_name = file_name.replace(\" \", \"_\")\n",
    "    new_path = os.path.join(os.path.dirname(path), new_file_name)\n",
    "    os.rename(path, new_path)\n",
    "\n",
    "    return new_path\n",
    "\n",
    "def normalize_text(text:str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize text by removing unnecessary whitespaces and converting unicode characters to ASCII.\n",
    "\n",
    "    Args:\n",
    "    - text (str): The text to normalize.\n",
    "\n",
    "    Returns:\n",
    "    - str: The normalized text.\n",
    "    \"\"\"\n",
    "    return unicodedata.normalize(\"NFKD\", text)\n",
    "\n",
    "def str_from_docx_path(docx_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Get all text from a docx file.\n",
    "\n",
    "    Args:\n",
    "    - doc_path (str): The path to the docx file.\n",
    "\n",
    "    Returns\n",
    "    - dict: A dictionary with keys:\n",
    "        - path (str): The path to the docx file.\n",
    "        - status_ok (bool): True if the extraction was successful, False if not.\n",
    "        - result (str): The extracted text if successful, the error message if not.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(docx_path, \"rb\") as file:\n",
    "            \n",
    "            document = Document(file)\n",
    "\n",
    "            paras = [para.text for para in document.paragraphs]\n",
    "        \n",
    "            return {\n",
    "                \"path\": docx_path,\n",
    "                \"status_ok\": True,\n",
    "                \"result\": \"\\n\".join(paras)\n",
    "            }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"path\": docx_path,\n",
    "            \"status_ok\": False,\n",
    "            \"result\": str(e)\n",
    "        }\n",
    "\n",
    "def str_from_doc_path(doc_path: list) -> dict:\n",
    "    \"\"\"\n",
    "    Get all text from a doc file.\n",
    "\n",
    "    Args:\n",
    "    - doc_path (str): The path to the doc file.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary with keys:\n",
    "        - path (str): The path to the doc file.\n",
    "        - status_ok (bool): True if the extraction was successful, False if not.\n",
    "        - result (str): The extracted text if successful, the error message if not.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text = textract.process(doc_path)\n",
    "        return {\n",
    "            \"path\": doc_path,\n",
    "            \"status_ok\": True,\n",
    "            \"result\": text.decode(\"utf-8\")\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"path\": doc_path,\n",
    "            \"status_ok\": False,\n",
    "            \"result\": str(e)\n",
    "        }\n",
    "\n",
    "def str_from_rtf_path(rtf_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Get all text from a rtf file.\n",
    "\n",
    "    Args:\n",
    "    - rtf_path (str): The path to the rtf file.\n",
    "\n",
    "    Returns\n",
    "    - dict: A dictionary with keys:\n",
    "        - path (str): The path to the rtf file.\n",
    "        - status_ok (bool): True if the extraction was successful, False if not.\n",
    "        - result (str): The extracted text if successful, the error message if not.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(rtf_path) as file:\n",
    "            content = file.read()\n",
    "            \n",
    "            return {\n",
    "                \"path\": rtf_path,\n",
    "                \"status_ok\": True,\n",
    "                \"result\": rtf_to_text(content)\n",
    "            }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"path\": rtf_path,\n",
    "            \"status_ok\": False,\n",
    "            \"result\": str(e)\n",
    "        }\n",
    "\n",
    "def str_from_file_path(file_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Get all text from a file.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): The path to the file.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary with keys:\n",
    "        - path (str): The path to the file.\n",
    "        - status_ok (bool): True if the extraction was successful, False if not.\n",
    "        - result (str): The extracted text if successful, the error message if not.\n",
    "    \"\"\"\n",
    "    \n",
    "    file_ext = os.path.splitext(file_path)[1].lower()\n",
    "\n",
    "    if file_ext == \".pdf\":\n",
    "        return str_from_pdf_path(file_path)\n",
    "    elif file_ext == \".docx\":\n",
    "        return str_from_docx_path(file_path)\n",
    "    elif file_ext == \".doc\":\n",
    "        return str_from_doc_path(file_path)\n",
    "    elif file_ext == \".rtf\":\n",
    "        return str_from_rtf_path(file_path)\n",
    "    else:\n",
    "        return {\n",
    "            \"path\": file_path,\n",
    "            \"status_ok\": False,\n",
    "            \"result\": f\"Unsupported file type: {file_ext}\"\n",
    "        }\n",
    "\n",
    "def txt_export_from_list_with_dics(input_list:list, output_folder: str) -> None:\n",
    "    \"\"\"\n",
    "    Export the text from a DataFrame to text files.\n",
    "\n",
    "    Args:\n",
    "    - innput_list (list): A list of dictionaries with keys:\n",
    "    - output_folder (str): The path to the output folder.\n",
    "    - extension (str): The file extension to use for the output files.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(input_list, columns=[\"path\", \"status_ok\", \"result\"])\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        if row[\"status_ok\"]:\n",
    "            file_ext = os.path.splitext(row[\"path\"])[1]\n",
    "            output_path = os.path.join(output_folder, os.path.basename(row[\"path\"]).replace(file_ext, \".txt\"))\n",
    "            with open(output_path, \"w\") as file:\n",
    "                file.write(row[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file paths for supported file types\n",
    "file_paths = file_paths_from_directory(input_folder, file_exts=[\".pdf\", \".docx\", \".doc\", \".rtf\", \".txt\"])\n",
    "\n",
    "# Process files in list\n",
    "all_results = [str_from_file_path(get_clean_file_name(file_path)) for file_path in file_paths]\n",
    "txt_export_from_list_with_dics(all_results, output_folder)\n",
    "\n",
    "# Copy txt files\n",
    "txt_file_paths = [path for path in file_paths if path.endswith(\".txt\")]\n",
    "for file_path in txt_file_paths:\n",
    "    new_path = get_clean_file_name(file_path)\n",
    "    os.rename(file_path, os.path.join(output_folder, os.path.basename(new_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON export\n",
    "\n",
    "- The data is exported from the database in JSON format\n",
    "- The text is split in chunks of 2000 characters\n",
    "- The Elements are: file_path and text_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text_files = file_paths_from_directory(output_folder, file_exts=[\".txt\"])\n",
    "\n",
    "results = []\n",
    "\n",
    "for file in all_text_files:\n",
    "    with open(file) as f:\n",
    "        text = f.read()\n",
    "\n",
    "        length = len(text)\n",
    "        for i in range(0, length, 2000):\n",
    "\n",
    "            results.append({\n",
    "                \"file_path\": os.path.basename(file),\n",
    "                \"text_section\": text[i:i+2000]\n",
    "            })\n",
    "\n",
    "text_df = pd.DataFrame(results)\n",
    "text_df.to_json(os.path.join(data_folder, \"text_data.json\"), orient=\"records\", indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
