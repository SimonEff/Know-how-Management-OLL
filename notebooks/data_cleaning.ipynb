{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import os\n",
    "from pprint import pprint\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import unicodedata\n",
    "\n",
    "# Third party\n",
    "import pandas as pd\n",
    "import fitz # PyMuPDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "working_directory = os.path.split(os.getcwd())\n",
    "\n",
    "data_folder = os.path.join(working_directory[0], \"data\")\n",
    "print(os.path.exists(data_folder))\n",
    "\n",
    "input_folder = os.path.join(working_directory[0], \"data\", \"unclean\")\n",
    "print(os.path.exists(input_folder))\n",
    "\n",
    "output_folder = os.path.join(working_directory[0], \"data\", \"clean\")\n",
    "print(os.path.exists(output_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def file_paths_from_directory(dir_path:str, abs_path:bool=False, file_exts:list=None, hidden:bool=False, sys_files:bool=False) -> list:\n",
    "    \"\"\"\n",
    "    Get a list of all files in a directory including subdirectories.\n",
    "\n",
    "    Args:\n",
    "    - dir_path (str): The path to the directory to search.\n",
    "    - hidden (list or None): Limit to specific file extension. Default is None.\n",
    "    - file_ext (bool): The file extension to search for. Default is None.\n",
    "    - abs_path (bool): Return absolute file paths. Default is False.\n",
    "    - hidden (bool): Include hidden files. Default is False.\n",
    "    - sys_files (bool): Include system files. Default is False.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of file paths. If abs_path is True, the file paths will be absolute. Otherwise, they will be relative.\n",
    "    \"\"\"\n",
    "    # Check if the directory exists\n",
    "    if not os.path.isdir(dir_path):\n",
    "        raise FileNotFoundError(f\"The directory '{dir_path}' does not exist.\")\n",
    "\n",
    "    # Get all files in the directory\n",
    "    file_list: list = []\n",
    "    for root, _, files in os.walk(dir_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_list.append(file_path)\n",
    "\n",
    "    # Remove spaces from the file names\n",
    "    ################# untested #################\n",
    "    for file_path in file_list:\n",
    "        get_clean_file_name(file_path)\n",
    "    ################# untested #################\n",
    "\n",
    "    # Filter the file list by file extension\n",
    "    if file_exts is not None:\n",
    "        _file_list: list = []\n",
    "        for file_ext in file_exts:\n",
    "            _file_list.extend([f for f in file_list if f.lower().endswith(file_ext)])\n",
    "        file_list = _file_list\n",
    "\n",
    "    # Filter the file list by hidden files\n",
    "    if not hidden:\n",
    "        file_list: list = [f for f in file_list if not os.path.basename(f).startswith(\".\")]\n",
    "\n",
    "    # Get the absolute file paths\n",
    "    if abs_path:\n",
    "        file_list: list = [os.path.abspath(f) for f in file_list]\n",
    "\n",
    "    # Filter the file list by system files\n",
    "    if not sys_files:\n",
    "        windows_sys_files = [\"desktop.ini\", \"thumbs.db\"]\n",
    "        mac_sys_files = [\".ds_store\"]\n",
    "        for sys_file in mac_sys_files + windows_sys_files:\n",
    "            file_list = [f for f in file_list if not os.path.basename(f).lower().startswith(sys_file)]\n",
    "\n",
    "    # Return the file list\n",
    "    return file_list\n",
    "\n",
    "def str_from_pdf_paths(pdf_paths: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get all text from a list of pdf files.\n",
    "    This function uses concurrent.futures.ProcessPoolExecutor to parallelize the extraction.\n",
    "    Uses PyMuPDF (fitz) as the pdf reader.\n",
    "\n",
    "    Args:\n",
    "    - pdf_paths (list): A list of paths to the pdf files.\n",
    "\n",
    "    Returns a DataFrame with columns:\n",
    "    - pdf_path (str): The path to the pdf file.\n",
    "    - status_ok (bool): True if the extraction was successful, False if not.\n",
    "    - result (str): The extracted text if successful, the error message if not.\n",
    "    \"\"\"\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        results = list(executor.map(str_from_pdf_path, pdf_paths))\n",
    "\n",
    "    return pd.DataFrame(results, columns=[\"pdf_path\", \"status_ok\", \"result\"])\n",
    "\n",
    "def str_from_pdf_path(pdf_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Get all text from a pdf file.\n",
    "    Uses PyMuPDF (fitz) as the pdf reader.\n",
    "\n",
    "    Returns dictionary with keys:\n",
    "    - status_ok: True if the extraction was successful, False if not.\n",
    "    - result: The extracted text if successful, the error message if not.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as file:\n",
    "            doc = fitz.open(file)\n",
    "            return {\n",
    "                \"pdf_path\": pdf_path,\n",
    "                \"status_ok\": True,\n",
    "                \"result\": \" \".join([page.get_text() for page in doc])\n",
    "            }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"pdf_path\": pdf_path,\n",
    "            \"status_ok\": False,\n",
    "            \"result\": str(e)\n",
    "        }\n",
    "    \n",
    "def get_clean_file_name(path: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove spaces from the file name.\n",
    "\n",
    "    Args:\n",
    "    - path (str): The path to the file.\n",
    "\n",
    "    Returns:\n",
    "    - str: The new path to the file.\n",
    "    \"\"\"\n",
    "    file_name = os.path.basename(path)\n",
    "    new_file_name = file_name.replace(\" \", \"_\")\n",
    "    new_path = os.path.join(os.path.dirname(path), new_file_name)\n",
    "    os.rename(path, new_path)\n",
    "\n",
    "    return new_path\n",
    "\n",
    "def normalize_text(text:str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize text by removing unnecessary whitespaces and converting unicode characters to ASCII.\n",
    "\n",
    "    Args:\n",
    "    - text (str): The text to normalize.\n",
    "\n",
    "    Returns:\n",
    "    - str: The normalized text.\n",
    "    \"\"\"\n",
    "    return unicodedata.normalize(\"NFKD\", text)\n",
    "\n",
    "\n",
    "def str_from_doc_path(doc_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(doc_path, \"rb\") as file:\n",
    "            \n",
    "\n",
    "            ################# untested #################\n",
    "\n",
    "\n",
    "            doc = ...\n",
    "            \n",
    "            \n",
    "            \n",
    "            return {\n",
    "                \"doc_path\": doc_path,\n",
    "                \"status_ok\": True,\n",
    "                \"result\": \" \".join([page.get_text() for page in doc])\n",
    "            }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"doc_path\": doc_path,\n",
    "            \"status_ok\": False,\n",
    "            \"result\": str(e)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnProcess-1:\n",
      "Process SpawnProcess-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mauruswollensak/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mauruswollensak/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mauruswollensak/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mauruswollensak/.pyenv/versions/3.10.13/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Users/mauruswollensak/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'str_from_pdf_path' on <module '__main__' (built-in)>\n",
      "  File \"/Users/mauruswollensak/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mauruswollensak/.pyenv/versions/3.10.13/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Users/mauruswollensak/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'str_from_pdf_path' on <module '__main__' (built-in)>\n",
      "Process SpawnProcess-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mauruswollensak/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mauruswollensak/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mauruswollensak/.pyenv/versions/3.10.13/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Users/mauruswollensak/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'str_from_pdf_path' on <module '__main__' (built-in)>\n",
      "Process SpawnProcess-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mauruswollensak/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mauruswollensak/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mauruswollensak/.pyenv/versions/3.10.13/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Users/mauruswollensak/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'str_from_pdf_path' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A child process terminated abruptly, the process pool is not usable anymore",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m file_paths \u001b[38;5;241m=\u001b[39m file_paths_from_directory(input_folder, file_exts\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# # PDF to text\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mstr_from_pdf_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_paths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m all_results \u001b[38;5;241m=\u001b[39m [str_from_pdf_path(get_clean_file_name(file_path)) \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m file_paths]\n\u001b[1;32m      8\u001b[0m pdf_texts \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(all_results, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpdf_path\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus_ok\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[8], line 74\u001b[0m, in \u001b[0;36mstr_from_pdf_paths\u001b[0;34m(pdf_paths)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03mGet all text from a list of pdf files.\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03mThis function uses concurrent.futures.ProcessPoolExecutor to parallelize the extraction.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m- result (str): The extracted text if successful, the error message if not.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m---> 74\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_from_pdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpdf_paths\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(results, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpdf_path\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus_ok\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/concurrent/futures/process.py:766\u001b[0m, in \u001b[0;36mProcessPoolExecutor.map\u001b[0;34m(self, fn, timeout, chunksize, *iterables)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunksize must be >= 1.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 766\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_process_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m                      \u001b[49m\u001b[43m_get_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _chain_from_iterable_of_lists(results)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/concurrent/futures/_base.py:610\u001b[0m, in \u001b[0;36mExecutor.map\u001b[0;34m(self, fn, timeout, chunksize, *iterables)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    608\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m timeout \u001b[38;5;241m+\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 610\u001b[0m fs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmit(fn, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39miterables)]\n\u001b[1;32m    612\u001b[0m \u001b[38;5;66;03m# Yield must be hidden in closure so that the futures are submitted\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;66;03m# before the first iterator value is required.\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult_iterator\u001b[39m():\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/concurrent/futures/_base.py:610\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    608\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m timeout \u001b[38;5;241m+\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 610\u001b[0m fs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39miterables)]\n\u001b[1;32m    612\u001b[0m \u001b[38;5;66;03m# Yield must be hidden in closure so that the futures are submitted\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;66;03m# before the first iterator value is required.\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult_iterator\u001b[39m():\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/concurrent/futures/process.py:720\u001b[0m, in \u001b[0;36mProcessPoolExecutor.submit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown_lock:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_broken:\n\u001b[0;32m--> 720\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m BrokenProcessPool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_broken)\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown_thread:\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcannot schedule new futures after shutdown\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mBrokenProcessPool\u001b[0m: A child process terminated abruptly, the process pool is not usable anymore"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "## PDF to text\n",
    "file_paths = file_paths_from_directory(input_folder, file_exts=[\".pdf\"])\n",
    "all_results = [str_from_pdf_path(get_clean_file_name(file_path)) for file_path in file_paths]\n",
    "\n",
    "pdf_texts = pd.DataFrame(all_results, columns=[\"pdf_path\", \"status_ok\", \"result\"])\n",
    "\n",
    "for _, row in pdf_texts.iterrows():\n",
    "    \n",
    "    new_filename = os.path.splitext(os.path.basename(row[\"pdf_path\"]))[0] + \".txt\"\n",
    "\n",
    "    new_path = os.path.join(output_folder, os.path.basename(new_filename))\n",
    "\n",
    "    with open(new_path, \"w\") as f:\n",
    "        f.write(row[\"result\"])\n",
    "\n",
    "## DOC adn DOCX to text\n",
    "file_paths = file_paths_from_directory(input_folder, file_exts=[\".doc\", \".docx\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON export\n",
    "\n",
    "[\n",
    "    {\n",
    "        \"file_path\": \"...\",\n",
    "        \"text_section\": \"...\"\n",
    "    },\n",
    "]\n",
    "\n",
    "Split in 2000 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text_files = file_paths_from_directory(output_folder, file_exts=[\".txt\"])\n",
    "\n",
    "results = []\n",
    "\n",
    "for file in all_text_files:\n",
    "    with open(file) as f:\n",
    "        text = f.read()\n",
    "\n",
    "        length = len(text)\n",
    "        for i in range(0, length, 2000):\n",
    "\n",
    "            results.append({\n",
    "                \"file_path\": os.path.basename(file),\n",
    "                \"text_section\": text[i:i+2000]\n",
    "            })\n",
    "\n",
    "text_df = pd.DataFrame(results)\n",
    "text_df.to_json(os.path.join(data_folder, \"text_data.json\"), orient=\"records\", indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
